{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKakfR0M5WcX"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "<center> <h1> Transformations & Actions on RDDs </h1> </center>\n",
        "\n",
        "In the notebook, we will implement different transformations and actions using Python.\n",
        "\n",
        "\n",
        "\n",
        "### `Transformations`\n",
        "\n",
        "\n",
        "We will do the following transformations in this notebook:\n",
        "\n",
        "* 1. **Map**\n",
        "* 2. **FlatMap**\n",
        "* 3. **Filter**\n",
        "* 4. **Distinct**\n",
        "* 5. **Union**\n",
        "* 6. **Intersection**\n",
        "\n",
        "\n",
        "### `Actions`\n",
        "\n",
        "\n",
        "We will do the following Actions in this notebook:\n",
        "\n",
        "* 1. **Collect**\n",
        "* 2. **Take**\n",
        "* 3. **Count**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### `IMPORTING THE REQUIRED LIBRARIES`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxC_NPp28Y_a",
        "outputId": "32e20e49-70ec-4c9e-fd66-0c5b587f48d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=c300891e79e70e95f2418a4a0d1bd2b9814d2eae196efccb3f1be8c523768b5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.context import SparkContext"
      ],
      "metadata": {
        "id": "TvsWmjF68_2P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "KpWWLSK39Mpb",
        "outputId": "6e5eb305-4e40-4424-ffb8-78e2fc20754c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-3-2dfc28fca47d>:1 ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2dfc28fca47d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    450\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-3-2dfc28fca47d>:1 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "GjLD0JoN9fsu",
        "outputId": "814b742c-f2af-4e7e-ba69-a3dc960e668c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c2d8c1fc578f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLiJlcFo5Wca"
      },
      "source": [
        "---\n",
        "---\n",
        "#### ` Problem Statement`\n",
        "\n",
        "Suppose there is an orgranization name **`Analytics 20`**. It has 2 different branches, one in **`India`** and another one is in **`Dubai`** We have generated a random data of the employees of this organization. One file **`analytics_20_india.txt`** contains the data of employees of India and another one **`analytics_20_dubai.txt`** that contains the data of employees of Dubai.\n",
        "\n",
        "Each line of the both the files contains 3 columns. First one is `Name of the employee`, second one is `Department Name` in which he/she works and last one is `Place Name` to which the employee belongs. Data is as shown below -\n",
        "\n",
        "<center><img src=\"images/rdd_op_dataset.png\"></center>\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "#### `Reading the file - analytics_20_india.txt`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india=sc.textFile('/content/analytics_20_india.txt')"
      ],
      "metadata": {
        "id": "_znz1-8h918W"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(analytics_india)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "8cg2Fbub-NeV",
        "outputId": "41b4ad36-2e8d-4cb0-889f-08bb6b460bef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwgvyWAT5Wca"
      },
      "source": [
        "---\n",
        "##### Once we read the file in the spark, it has been converted into an RDD.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "#### `Action - collect`\n",
        "\n",
        "**collect** action will return the complete output.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all Records\n",
        "analytics_india.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm-Otoxj-_E4",
        "outputId": "50e14a3b-21d6-44a9-8f3d-11fd71f25df9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Keaton Data_Science India',\n",
              " 'Idona Data_Science Australia',\n",
              " 'Janna HR India',\n",
              " 'Damon Data_Science India',\n",
              " 'Rahim Marketing India',\n",
              " 'Audrey Data_Science India',\n",
              " 'Irma HR Dubai',\n",
              " 'Tatum HR India',\n",
              " 'Acton Data_Science India',\n",
              " 'Ainsley Data_Science India',\n",
              " 'Phillip Data_Science India',\n",
              " 'Maite Marketing India',\n",
              " 'Kevyn Marketing Australia',\n",
              " 'Vielka HR India',\n",
              " 'Risa Operations India',\n",
              " 'Jael Accounts Dubai',\n",
              " 'Erich Data_Science India',\n",
              " 'Pearl Operations Australia',\n",
              " 'Francesca Data_Science India',\n",
              " 'Ross Sales India',\n",
              " 'Tarik HR Dubai',\n",
              " 'Lev HR India',\n",
              " 'Nerea Accounts India',\n",
              " 'Halla Sales India',\n",
              " 'Daquan Legal India',\n",
              " 'Ivan HR India',\n",
              " 'Venus HR India',\n",
              " 'Lareina Legal India',\n",
              " 'Orlando Sales Australia',\n",
              " 'Denise Accounts India',\n",
              " 'Alvin Accounts Dubai',\n",
              " 'Rafael Data_Science Australia',\n",
              " 'Whoopi Data_Science Australia',\n",
              " 'Norman Legal Dubai',\n",
              " 'Forrest Sales Dubai',\n",
              " 'Sigourney Legal India',\n",
              " 'Stone Legal Scotland',\n",
              " 'Todd Sales India',\n",
              " 'Jerome Sales India',\n",
              " 'Signe HR India',\n",
              " 'Xavier Legal India',\n",
              " 'Kevin Customer_Support India',\n",
              " 'Michelle Customer_Support India',\n",
              " 'Lyle Customer_Support Dubai',\n",
              " 'Brendan Data_Science Australia',\n",
              " 'Melvin Data_Science Australia',\n",
              " 'Ignacia Customer_Support India',\n",
              " 'Lenore HR India']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YOocdci5Wcb"
      },
      "source": [
        "---\n",
        "---\n",
        "#### `Action - take`\n",
        "\n",
        "**take** action will return the top n (takes an integer as a parameter) results of the query. It the similar to the head funciton of pandas.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take 5 records\n",
        "analytics_india.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiy2Q-kc_YZu",
        "outputId": "c2532e27-bf2b-4db1-b34c-054dad28bf8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Keaton Data_Science India',\n",
              " 'Idona Data_Science Australia',\n",
              " 'Janna HR India',\n",
              " 'Damon Data_Science India',\n",
              " 'Rahim Marketing India']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdEmbKNt5Wcb"
      },
      "source": [
        "---\n",
        "---\n",
        "#### `Transformation - map`\n",
        "\n",
        "**map** transformation does the same operation on each of the object.\n",
        "\n",
        "We will split each line into a list of words using **map**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map transformation-Tokenize all records\n",
        "analytics_india_map = analytics_india.map(lambda x: x.split(' '))"
      ],
      "metadata": {
        "id": "EuBZ0RI7_xgs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tAZWbujASmz",
        "outputId": "7d8bab2a-deab-4e1f-fdb1-6f6fab877fff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[3] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india_map.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRhabPaJAn8S",
        "outputId": "4008f23c-e4eb-4923-ff24-d1e0215edd05"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Keaton', 'Data_Science', 'India'],\n",
              " ['Idona', 'Data_Science', 'Australia'],\n",
              " ['Janna', 'HR', 'India'],\n",
              " ['Damon', 'Data_Science', 'India'],\n",
              " ['Rahim', 'Marketing', 'India']]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikjh7iF35Wcb"
      },
      "source": [
        "---\n",
        "---\n",
        "#### `Transformation - distinct`\n",
        "\n",
        "**distinct** is used to find the unique elements in the RDD.\n",
        "\n",
        "Find out the list of unique places of origin of the employees in the India branch.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create rdd with only country value\n",
        "analytics_india_places= analytics_india_map.map(lambda x : x[2])"
      ],
      "metadata": {
        "id": "cHXPh61NC3lW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india_places"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O__AZCzWDUS5",
        "outputId": "87f103cc-4184-480a-86ed-fcdb832d2411"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[12] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india_places.take(6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq_HDr80DZeq",
        "outputId": "d4aeec06-55eb-4c9e-e4fe-aac49019286d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['India', 'Australia', 'India', 'India', 'India', 'India']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the distinct transformation\n",
        "analytics_india_distinct_places =analytics_india_places.distinct()"
      ],
      "metadata": {
        "id": "8b-qYzccDtv6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Name of the distinct countrie of people working for india branch\n",
        "analytics_india_distinct_places.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J29g4Cw2EFYT",
        "outputId": "5dd853f4-7cba-47ee-892b-55f39208e368"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['India', 'Australia', 'Dubai', 'Scotland']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use count action to find out total places\n",
        "analytics_india_distinct_places.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT9zptNSEcCS",
        "outputId": "1f8554be-2fc3-4374-a19d-92f133c18f2e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dOoJASf5Wcb"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#### `Transformation - filter`\n",
        "\n",
        "**filter** transformation only returns the elements which satisfies the given condition.\n",
        "\n",
        "Find out the data of the people who belong to the **India**.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india_map.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzJfWXeUEy7g",
        "outputId": "88180172-40b0-4da0-bd89-fa9af6a7b56f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Keaton', 'Data_Science', 'India'],\n",
              " ['Idona', 'Data_Science', 'Australia'],\n",
              " ['Janna', 'HR', 'India'],\n",
              " ['Damon', 'Data_Science', 'India'],\n",
              " ['Rahim', 'Marketing', 'India']]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the people who belongs to the india\n",
        "analytics_india_employee_india = analytics_india_map.filter(lambda x :x[2]== 'India')"
      ],
      "metadata": {
        "id": "aGz5QMKvE6ky"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#analytics_india_employee_india.take(5)\n",
        "analytics_india_employee_india.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWxKUFjdFnQa",
        "outputId": "9345d6e1-6c15-4b75-82e6-403d000c0535"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Keaton', 'Data_Science', 'India'],\n",
              " ['Janna', 'HR', 'India'],\n",
              " ['Damon', 'Data_Science', 'India'],\n",
              " ['Rahim', 'Marketing', 'India'],\n",
              " ['Audrey', 'Data_Science', 'India'],\n",
              " ['Tatum', 'HR', 'India'],\n",
              " ['Acton', 'Data_Science', 'India'],\n",
              " ['Ainsley', 'Data_Science', 'India'],\n",
              " ['Phillip', 'Data_Science', 'India'],\n",
              " ['Maite', 'Marketing', 'India'],\n",
              " ['Vielka', 'HR', 'India'],\n",
              " ['Risa', 'Operations', 'India'],\n",
              " ['Erich', 'Data_Science', 'India'],\n",
              " ['Francesca', 'Data_Science', 'India'],\n",
              " ['Ross', 'Sales', 'India'],\n",
              " ['Lev', 'HR', 'India'],\n",
              " ['Nerea', 'Accounts', 'India'],\n",
              " ['Halla', 'Sales', 'India'],\n",
              " ['Daquan', 'Legal', 'India'],\n",
              " ['Ivan', 'HR', 'India'],\n",
              " ['Venus', 'HR', 'India'],\n",
              " ['Lareina', 'Legal', 'India'],\n",
              " ['Denise', 'Accounts', 'India'],\n",
              " ['Sigourney', 'Legal', 'India'],\n",
              " ['Todd', 'Sales', 'India'],\n",
              " ['Jerome', 'Sales', 'India'],\n",
              " ['Signe', 'HR', 'India'],\n",
              " ['Xavier', 'Legal', 'India'],\n",
              " ['Kevin', 'Customer_Support', 'India'],\n",
              " ['Michelle', 'Customer_Support', 'India'],\n",
              " ['Ignacia', 'Customer_Support', 'India'],\n",
              " ['Lenore', 'HR', 'India']]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qazGL_Dc5Wcb"
      },
      "source": [
        "---\n",
        "\n",
        "Let's find out the data of the people who belongs to **Dubai** and are in **HR** department.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the filter transformation dubai and HR\n",
        "analytics_india_filtered_data = analytics_india_map.filter(lambda x : (x[1]=='HR')&(x[2]=='Dubai'))"
      ],
      "metadata": {
        "id": "fM86tY3kGPAX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india_filtered_data.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPhdz5sqHBSa",
        "outputId": "3f243eb6-3034-4a25-ac0e-d2401d2b0944"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Irma', 'HR', 'Dubai'], ['Tarik', 'HR', 'Dubai']]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6fCDDzM5Wcb"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#### `Transformation - flatmap`\n",
        "\n",
        "* We saw **map** function does a one-to-one transformation.\n",
        "> * It transforms each element of a collection into one element of the resulting collection.\n",
        "\n",
        "<center><img src =\"images/map_transformation.png\"></center>\n",
        "\n",
        "* In the **flatmap** transformation, we will see that instead of multiple lists of each line it will return a single list of output.\n",
        "> * Spark **flatMap** function expresses a one-to-many transformation.\n",
        "\n",
        "Let's see the difference.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6OYxRmXHfde",
        "outputId": "23a3af91-1927-46ad-83ff-26274c76c2df"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Keaton Data_Science India',\n",
              " 'Idona Data_Science Australia',\n",
              " 'Janna HR India',\n",
              " 'Damon Data_Science India',\n",
              " 'Rahim Marketing India']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatmap transformation - tokenize\n",
        "analytics_india_flatmap = analytics_india.flatMap(lambda x : x.split(' '))"
      ],
      "metadata": {
        "id": "Ba3WQeIpHl36"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india_flatmap.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRB0N6MiICBt",
        "outputId": "88f48271-b624-435c-c76d-10ed49ee3b14"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Keaton',\n",
              " 'Data_Science',\n",
              " 'India',\n",
              " 'Idona',\n",
              " 'Data_Science',\n",
              " 'Australia',\n",
              " 'Janna',\n",
              " 'HR',\n",
              " 'India',\n",
              " 'Damon']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india_map.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ_LbpMVIVyp",
        "outputId": "721e7ffe-fba5-45ce-fcfe-0e703a287437"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Keaton', 'Data_Science', 'India'],\n",
              " ['Idona', 'Data_Science', 'Australia'],\n",
              " ['Janna', 'HR', 'India'],\n",
              " ['Damon', 'Data_Science', 'India'],\n",
              " ['Rahim', 'Marketing', 'India']]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJD2MTcT5Wcc"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#### `Transformation - union`\n",
        "\n",
        "Use **union** transformation to find out all the places of origin from both branches - India and Dubai.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_dubai = sc.textFile('/content/analytics_20_dubai.txt')"
      ],
      "metadata": {
        "id": "lnbFmHMdI3Ao"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_dubai.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khMqqwnAJCx2",
        "outputId": "ee3cf5ca-3cad-4008-cc6e-e3a2b6b0e17f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Leo Customer_Support Scotland',\n",
              " 'Cyrus Customer_Support India',\n",
              " 'Jolie Sales India',\n",
              " 'Susan HR Australia',\n",
              " 'Azalia Customer_Support Dubai']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map Transformation - Tokenize\n",
        "analytics_dubai_map = analytics_dubai.map(lambda x: x.split(' '))"
      ],
      "metadata": {
        "id": "M3ZZwjDAJPb6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_dubai_map.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G8_Nan2J1Pn",
        "outputId": "c8b356a0-dfff-4afb-cd47-745ee19a2c49"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Leo', 'Customer_Support', 'Scotland'],\n",
              " ['Cyrus', 'Customer_Support', 'India'],\n",
              " ['Jolie', 'Sales', 'India'],\n",
              " ['Susan', 'HR', 'Australia'],\n",
              " ['Azalia', 'Customer_Support', 'Dubai']]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select distinct places from analytics_20_dubai\n",
        "analytics_dubai_places = analytics_dubai_map.map(lambda x: x[2])"
      ],
      "metadata": {
        "id": "EnALKQz0KBOH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_dubai_places.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3I5eBshKdLy",
        "outputId": "0e3144d7-71a7-4f20-f3cd-b69ebf708346"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Scotland', 'India', 'India', 'Australia', 'Dubai']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get distinct places\n",
        "analytics_dubai_distinct_places=analytics_dubai_places.distinct()"
      ],
      "metadata": {
        "id": "aAz1zWD1Kndc"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_dubai_distinct_places.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE-dXDiiK64H",
        "outputId": "672cb676-50a1-4ff6-d45c-9c52a79b3c98"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Scotland', 'India', 'Australia', 'Dubai', 'South_Africa']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_india_distinct_places.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5olfSKdLC5y",
        "outputId": "281640df-f550-4d62-bbd5-d1c3ddfc9af1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['India', 'Australia', 'Dubai', 'Scotland']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Union places from two branches\n",
        "union_places = analytics_india_distinct_places.union(analytics_dubai_distinct_places)"
      ],
      "metadata": {
        "id": "SD4n2ueqLPBK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total\n",
        "union_places.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhX0fAQHLlN-",
        "outputId": "e882f396-fba8-4779-b1c1-3c34f0f71670"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['India',\n",
              " 'Australia',\n",
              " 'Dubai',\n",
              " 'Scotland',\n",
              " 'Scotland',\n",
              " 'India',\n",
              " 'Australia',\n",
              " 'Dubai',\n",
              " 'South_Africa']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3V07Ser5Wcc"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "#### `Transformation - intersection`\n",
        "\n",
        "Use **intersection** transformation to find out the common places of origin of the employees from both branches - India and Dubai.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Intersection of Both RDDs of unique place\n",
        "common_places= analytics_india_distinct_places.intersection(analytics_dubai_distinct_places)"
      ],
      "metadata": {
        "id": "KVuPAbAuLvTq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect the results\n",
        "common_places.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4i1bzpQMHZX",
        "outputId": "04bbbeb3-893c-4d1d-8b04-0fbdea60a314"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dubai', 'India', 'Australia', 'Scotland']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}